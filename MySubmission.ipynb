{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82324535",
   "metadata": {},
   "source": [
    "# Solving Contract Classification challenge "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c781bd21",
   "metadata": {},
   "source": [
    "* Since the instructor claims that we can reach above 90% accuracy without using ML techniques, then let's give it a try.\n",
    "* --->The code was not optimized for running time <---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ee1ce2",
   "metadata": {},
   "source": [
    "* let's start with importing all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "097aa5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np \n",
    "from functools import partial\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sys.path.append('../src/')\n",
    "# %matplotlib inline\n",
    "import re\n",
    "from uatt import submit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30749ee8",
   "metadata": {},
   "source": [
    "Now I'm defining some useful function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "42fc0250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def theMostRepitable(dic):\n",
    "    TwentyMostRepitableWors = []\n",
    "    for i in range(20):\n",
    "        val = max(dic.values())\n",
    "        \n",
    "        for j in dic.keys():\n",
    "            if dic[j] == val:\n",
    "                key = j\n",
    "                break\n",
    "            \n",
    "        TwentyMostRepitableWors.append(key)\n",
    "        dic.pop(key)\n",
    "        \n",
    "    return TwentyMostRepitableWors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfda375",
   "metadata": {},
   "source": [
    "* My personal details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "17665408",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submit = partial(submit, \"Yaniv Cohen\", \"Elbit\", \"yanivavoda@gmail.com\", \"0524321552\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920ede19",
   "metadata": {},
   "source": [
    "* Now, let's read the data from a zip file provided by the instructor. \n",
    "\n",
    "Note: I am reading now only the trainig data (for now) and taking a look over the structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "7e03cc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id       label                                            content\n",
      "2841  22250         rsu  Exhibit 10.4 \\n\\nNMT MEDICAL, INC. \\n\\n\\n  \\nN...\n",
      "2721  21050         rsu  Exhibit 99.3 \\n\\n\\n\\nWHEREAS, Beverly N. Hawki...\n",
      "2500  18840         rsu  EXHIBIT 10.1\\n\\nRestricted Stock Agreement One...\n",
      "111   01120         SPA  EXHIBIT 10.1\\n\\n\\n\\nThis Stock Purchase Agreem...\n",
      "2081  16040  employment  Exhibit 10.6\\n\\n\\n\\nTHIS EMPLOYMENT AGREEMENT ...\n",
      "3257  26410         rsu  Exhibit 10.21 \\n\\n\\n\\nTHIS AGREEMENT, made as ...\n",
      "3189  25730         rsu  Exhibit 10.5  \\n\\n\\nPINNACLE FINANCIAL PARTNER...\n",
      "93    00940         SPA    \\n\\n\\n  \\n\\n\\n\\n\\n  \\n\\n\\nTHIS STOCK PURCHAS...\n",
      "3305  26890         rsu  Exhibit 10.3 \\n\\nAUXILIUM PHARMACEUTICALS, INC...\n",
      "324   40910      bylaws  * * *\\n\\nAMENDED AND RESTATED\\n\\n\\n\\nOF\\n\\nWHI...\n",
      "The size of the training data is: 4427\n"
     ]
    }
   ],
   "source": [
    "## Read the data \n",
    "data = []\n",
    "with ZipFile(\"../data/data.zip\") as z:\n",
    "    for fname in z.namelist():\n",
    "        if not fname.endswith('.txt') or not fname.startswith('data'):\n",
    "            continue\n",
    "        content = z.read(fname).decode('utf8')\n",
    "        label, idx = fname[5:-4].split('-', 1)\n",
    "        data.append((idx,label,content,))\n",
    "df_train0 = pd.DataFrame(data, columns=(\"id\", \"label\", \"content\"))\n",
    "print(df_train0.sample(10))\n",
    "print(\"The size of the training data is: %.i\" % len(df_train0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ed9bf4",
   "metadata": {},
   "source": [
    "* Let's take a look at the distribution of the data based on the contract class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "f33859a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "### PLot the distribution \n",
    "df_train0[\"label\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f272a815",
   "metadata": {},
   "source": [
    "* Next, let's see if we have some missing data in our dataset. Additionally, let's examine the uniqueness of each column. (As we can see there is no duplication nor missing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "d64ac52b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Check if you have None in the data:\n",
      "id         0\n",
      "label      0\n",
      "content    0\n",
      "dtype: int64\n",
      "unique values of id: 4427, dataType: <class 'str'>\n",
      "unique values of label: 6, dataType: <class 'str'>\n",
      "unique values of content: 4396, dataType: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCheck if you have None in the data:\")\n",
    "print(pd.isnull(df_train).sum())\n",
    "# check uniqness\n",
    "col = df_train0.columns.values\n",
    "\n",
    "for head in df_train0.columns.values:\n",
    "    \n",
    "    print('unique values of %s: %i, dataType: %s' % (head, df_train0[head].nunique(), type(df_train0[head][1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f5332d",
   "metadata": {},
   "source": [
    "* As we can see we have 6 classes, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3aa8c1",
   "metadata": {},
   "source": [
    "* Next, let's shuffle the training data into train and validation sets. This move is necessary to check ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "5cb03e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = len(df_train0)\n",
    "df_train0 = df_train0.sample(frac=1).reset_index(drop=True) ### <---shuffle step\n",
    "\n",
    "df_train = df_train = df_train0.copy(deep = True)  \n",
    "# see the warning note at the end of this notebook , df_train0.iloc[:int(0.9*x)]\n",
    "df_train_validation = df_train0.iloc[int(0.9*x):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16f8c49",
   "metadata": {},
   "source": [
    "## The core of the proposed technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7015cd1c",
   "metadata": {},
   "source": [
    "* The technique presented here is based on finding unique words for each class. Those words will be used as a fingerprint for our classification. In other words, for each class, we'll have a unique vector that contains the most frequent words of this class, and which are not presented in any other class. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbc9067",
   "metadata": {},
   "source": [
    "* Mathematically:\n",
    "\n",
    "$\\forall w_{i}^{j} \\in W^{j}$, $w_{i}^{j} \\notin W  = \\{W^{c} | c \\neq j \\}$ \n",
    "\n",
    "where $j$ is the class number, $j \\in \\{1,2,3,4,5,6\\}$, $i$ is the word's index in the vector of the class, $i\\in\\{1,...,20\\}$, and $W^{j}$ is a vector of 20 unique words of the class j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "6196c2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing unique words for each class... \n",
      "\n",
      "Cheking unique words for the class:  SPA\n",
      "Cheking unique words for the class:  bylaws\n",
      "Cheking unique words for the class:  credit\n",
      "Cheking unique words for the class:  employment\n",
      "Cheking unique words for the class:  rra\n",
      "Cheking unique words for the class:  rsu\n",
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "### check the most repitable words\n",
    "print(\"Analyzing unique words for each class... \\n\")\n",
    "all_labels = sorted(df_train[\"label\"].unique())\n",
    "all_classes_dic = {}\n",
    "for label_i in all_labels :\n",
    "    print(\"Cheking unique words for the class: \",label_i)\n",
    "    f = df_train.loc[(df_train['label'] == label_i)]\n",
    "    f.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    counterDictionary = {} \n",
    "            \n",
    "    for i in range(len(f)):\n",
    "        str_i = f.iloc[i][\"content\"]\n",
    "        list_of_words = str_i.split()\n",
    "        words_p = []  \n",
    "        for j in list_of_words:\n",
    "            try:\n",
    "                float(j)\n",
    "            except:\n",
    "                \n",
    "                if j not in [\"a\", \"The\",\"the\", \"and\", \"is\", \"are\", \"of\", \"by\", \"this\", \"shall\", \n",
    "                             \"as\", \"with\", \"such\"] and j not in words_p:\n",
    "                    \n",
    "                    counterDictionary[j] = counterDictionary.get(j, 0) + 1\n",
    "                    \n",
    "                words_p.append(j)\n",
    "    \n",
    "    all_classes_dic[label_i] = counterDictionary\n",
    "    \n",
    "count  = 0  \n",
    "vec_keys_label = list(all_classes_dic.keys()) \n",
    "d_new_of_optimal_words= {} \n",
    "\n",
    "for ij in range(len(all_classes_dic.keys())):\n",
    "    label_i = vec_keys_label[ij]\n",
    "    dic = all_classes_dic[label_i]\n",
    "    all_other_keys = vec_keys_label[:ij] + vec_keys_label[ij+1:]\n",
    "    d = {}\n",
    "    value = 0\n",
    "\n",
    "    [d.update(all_classes_dic[kj]) for kj in all_other_keys]\n",
    "    \n",
    "    d_keys_unique = {}\n",
    "    for key2 in dic.keys():\n",
    "        if key2 not in  d.keys():\n",
    "\n",
    "            if dic[key2] >= 5:\n",
    "                d_keys_unique[key2] = dic[key2]\n",
    "            \n",
    "            if value < dic[key2]:\n",
    "                optimal_key = key2\n",
    "                value = dic[key2]\n",
    "                \n",
    "    d_new_of_optimal_words[label_i] = d_keys_unique  #(optimal_key, value)\n",
    "\n",
    "print(\"Finish!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd57b3a9",
   "metadata": {},
   "source": [
    "## Test step:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a800b3af",
   "metadata": {},
   "source": [
    "* Now that we have for each class 20 unique words, let's make some predictions over our validation set.\n",
    "* The idea is as follows, for each class I will check how many unique words are present in the given contract, the class with the highest match will be defined as the class of the examined contract. In the case of zero matches for all 6 classes, I am going to classify it as \"rsu\" class based on the fact that it is the most common contract class in our data.\n",
    "\n",
    "* Note: Since 'rra' class is very rare, then I will define 'rra' class only if we reach higher than 25% match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "94d51235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id label                                            content prediction\n",
      "307  33640     0  Exhibit 10.2\\n\\nQUALITY SYSTEMS, INC.\\n\\nOUTSI...          0\n",
      "4    01720     3  Exhibit No.: 10.2  \\n  \\n\\n\\nThis Agreement, d...          3\n",
      "220  27750     0  Exhibit 10.87\\n\\nCharles Romeo\\n\\nOptionee\\n\\n...          0\n",
      "204  00200     3  REGULATION S \\n\\n\\n\\nThis Regulation S Stock P...          3\n",
      "41   07160     1    \\nQuickLinks \\-- Click here to rapidly navig...          1\n",
      "382  26570     0  Exhibit 10.2 \\n\\n1996 STOCK INCENTIVE PLAN OF ...          0\n",
      "36   11660     1  EXHIBIT 10.1\\n\\n\\n\\n  \\n\\n\\nThis Employment Ag...          1\n",
      "126  29100     0  * * *\\n\\nExhibit 10.2\\n\\n\\n\\nMAGNUM HUNTER RES...          0\n",
      "97   33910     0  Exhibit 10.3  \\n\\n\\nSTANDARD FORM OF\\n\\nSCIENT...          0\n",
      "310  09550     1  Exhibit 10.a.\\n\\n\\n  \\n\\n\\nBETWEEN  \\n  \\n\\n\\n...          1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#### check yoursel\n",
    "\n",
    "\n",
    "twenty_most_repitable_per_class = {}\n",
    "classes_all = ['rsu', 'employment', 'bylaws', 'SPA', 'credit', 'rra']\n",
    "\n",
    "for c in classes_all:\n",
    "    dic = d_new_of_optimal_words[c]\n",
    "    dic_per_class = theMostRepitable(dic.copy())\n",
    "    twenty_most_repitable_per_class[c] =  dic_per_class\n",
    "\n",
    "df_train_validation.reset_index(drop = True, inplace = True)\n",
    "Vec = [\"rsu\" for l in range(len(df_train_validation))]\n",
    "df_train_validation.insert(np.shape(df_train_validation)[1], \"prediction\", Vec )\n",
    "#[\"label2\"] = [\"rsu\" for l in range(len(df_train_validation))] \n",
    "\n",
    "\n",
    "for i in range(len(df_train_validation)):\n",
    "        str_i = df_train_validation.iloc[i][\"content\"]\n",
    "        list_of_words = str_i.split()\n",
    "        \n",
    "        ## now lets check fitting \n",
    "        value = 0\n",
    "        for c in classes_all:\n",
    "            dic = twenty_most_repitable_per_class[c]\n",
    "            count = 0\n",
    "            \n",
    "            for j in dic:\n",
    "                # print(j in str_i)\n",
    "                wordi = ''.join(e for e in j if e.isalnum())\n",
    "                # print(wordi)\n",
    "                if wordi in str_i:\n",
    "                    count += 1\n",
    "            # print(count)   \n",
    "            if value < count :\n",
    "                value = float(count) \n",
    "                if c == 'rra' and count > 5:\n",
    "                    df_train_validation.loc[i][\"prediction\"] = c\n",
    "                    # print(\"value\", value, c)\n",
    "                elif c!= 'rra':\n",
    "                    \n",
    "                    df_train_validation.loc[i][\"prediction\"] = c\n",
    "    \n",
    "\n",
    "classes_all = ['rsu', 'employment', 'bylaws', 'SPA', 'credit', 'rra']\n",
    "for i in range(len(df_train_validation)):\n",
    "    for j in range(len(classes_all)):\n",
    "        if classes_all[j] == df_train_validation.iloc[i][\"label\"]:\n",
    "            df_train_validation.iloc[i][\"label\"] = j\n",
    "        if classes_all[j] ==  df_train_validation.iloc[i][\"prediction\"]:\n",
    "            df_train_validation.iloc[i][\"prediction\"] = j\n",
    " \n",
    "\n",
    "print(df_train_validation.sample(10))\n",
    "                \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa41db0f",
   "metadata": {},
   "source": [
    "* Now let's look at the accuracy of this primitive classifier, and check it's confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "fef8b2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.9142212189616253\n",
      "\n",
      " confusion matrix: \n",
      "\n",
      "[[181  14   3   1   0   0]\n",
      " [  0 142   0   0   0   0]\n",
      " [  5   3  40   1   0   2]\n",
      " [  0   2   0  12   0   2]\n",
      " [  2   1   0   0  10   0]\n",
      " [  2   0   0   0   0  20]]\n"
     ]
    }
   ],
   "source": [
    "            \n",
    "y_true = list(df_train_validation[\"label\"])\n",
    "y_pred = list(df_train_validation[\"prediction\"])\n",
    "good =0 \n",
    "for m in range(len(y_pred)):\n",
    "    if y_pred[m] == y_true[m]:\n",
    "        good += 1\n",
    "        \n",
    "print(\"acc: \", good/len(y_pred))\n",
    "print(\"\\n confusion matrix: \\n\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff2606d",
   "metadata": {},
   "source": [
    "## Let's try to make it better by using \"manual mode\" based on the data produced in the previous steps.\n",
    "\n",
    "* This move is based on the most common words of  \"rsu\" and \"bylaw\" classes\n",
    "* let's check again the accuracy and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "180d4e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.9232505643340858\n",
      "\n",
      " confusion matrix: \n",
      "\n",
      "[[185  10   3   1   0   0]\n",
      " [  0 141   1   0   0   0]\n",
      " [  5   3  41   1   0   1]\n",
      " [  0   2   0  12   0   2]\n",
      " [  2   1   0   0  10   0]\n",
      " [  2   0   0   0   0  20]]\n",
      "\n",
      " Nice!! we have a better results! and we reach above 90%!! \n",
      "\n",
      "Ignore the SettingWithCopyWarning bellow!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yc/anaconda3/envs/tf_2_3/lib/python3.6/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n",
      "/home/yc/anaconda3/envs/tf_2_3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/yc/anaconda3/envs/tf_2_3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/yc/anaconda3/envs/tf_2_3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/yc/anaconda3/envs/tf_2_3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/yc/anaconda3/envs/tf_2_3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_train_validation.loc[df_train_validation[\"content\"].str.contains(\"Optionee.\"),\"prediction\"] = 0 # 0 is \"rsu\"\n",
    "df_train_validation.loc[df_train_validation[\"content\"].str.contains(\"Grantee\"), \"prediction\"] = 0 # 0 is\"rsu\"\n",
    "df_train_validation.loc[df_train_validation[\"content\"].str.contains(\"PARTICIPANT\"), \"prediction\"] = 0 # 0 is \"rsu\"\n",
    "df_train_validation.loc[df_train_validation[\"content\"].str.contains(\"quorum\", flags = re.I, regex = True),\"prediction\"]  = 2#'bylaws'\n",
    "df_train_validation.loc[df_train_validation[\"content\"].str.contains(\"Vacancies.\"),\"prediction\"]  = 2 #\"bylaws\"\n",
    "            \n",
    "y_true = list(df_train_validation[\"label\"])\n",
    "y_pred = list(df_train_validation[\"prediction\"])\n",
    "\n",
    "good =0 \n",
    "for m in range(len(y_pred)):\n",
    "    if y_pred[m] == y_true[m]:\n",
    "        good += 1\n",
    "        \n",
    "print(\"acc: \", good/len(y_pred))\n",
    "print(\"\\n confusion matrix: \\n\")\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(\"\\n Nice!! we have a better results! and we reach above 90%!! \\n\")\n",
    "print(\"Ignore the SettingWithCopyWarning bellow!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40e7455",
   "metadata": {},
   "source": [
    "### Now let's import the test data and test our classifier\n",
    "* Since the \"manual mode\" was a success we will apply it also on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "2277daae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.90754257907543\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data = []\n",
    "with ZipFile(\"../data/test_data.zip\") as z:\n",
    "    for fname in z.namelist():\n",
    "        content = z.read(fname).decode('utf8')\n",
    "        if not fname.endswith('.txt') or not fname.startswith('test'):\n",
    "            continue\n",
    "        idx = fname[5:-4]\n",
    "        data.append((idx,content,))\n",
    "df_test = pd.DataFrame(data, columns=(\"id\", \"content\"))\n",
    "df_test.sample(10)\n",
    "df_test[\"label\"] = \"rsu\" #### 0.7627\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(df_test)):\n",
    "        str_i = df_test.iloc[i][\"content\"]\n",
    "        list_of_words = str_i.split()\n",
    "        \n",
    "        ## now lets check fitting \n",
    "        value = 0\n",
    "        for c in classes_all:\n",
    "            dic = twenty_most_repitable_per_class[c]\n",
    "            count = 0\n",
    "            \n",
    "            for j in dic:\n",
    "                # print(j in str_i)\n",
    "                wordi = ''.join(e for e in j if e.isalnum())\n",
    "                # print(wordi)\n",
    "                if wordi in str_i:\n",
    "                    count += 1\n",
    "            # print(count)   \n",
    "            if value < count :\n",
    "                value = float(count) \n",
    "                if c == 'rra' and count > 5:\n",
    "                    df_test.loc[i][\"label\"] = c\n",
    "                    # print(\"value\", value, c)\n",
    "                elif c == 'credit' and count> 5:\n",
    "                    df_test.loc[i][\"label\"] = c\n",
    "                elif c!= 'rra' and count >=2:\n",
    "                    \n",
    "                    df_test.loc[i][\"label\"] = c\n",
    "                \n",
    "df_test.loc[df_test[\"content\"].str.contains(\"Optionee.\"), \"label\"] = \"rsu\"\n",
    "df_test.loc[df_test[\"content\"].str.contains(\"Grantee\"), \"label\"] = \"rsu\"\n",
    "df_test.loc[df_test[\"content\"].str.contains(\"PARTICIPANT\"), \"label\"] = \"rsu\"\n",
    "df_test.loc[df_test[\"content\"].str.contains(\"quorum\", flags = re.I, regex = True),\"label\"]  = 'bylaws'\n",
    "df_test.loc[df_test[\"content\"].str.contains(\"Vacancies.\"),\"label\"]  = 'bylaws'\n",
    "\n",
    "\n",
    " \n",
    "submission = dict(df_test[[\"id\",\"label\"]].values)\n",
    "submission_name = \"YC\"\n",
    "acc = my_submit(submission_name, submission)\n",
    "\n",
    "print(\"acc: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24cd105",
   "metadata": {},
   "source": [
    "## Let's check the Leaderboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "1b6904bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://goren.ml/uattcontract/?mCLNSxo=cgtepyC\" target=\"_blank\">Go to Leaderboard</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random, string\n",
    "from IPython.display import HTML\n",
    "rand_str = lambda: \"\".join(random.sample(string.ascii_letters,7))\n",
    "HTML('<a href=\"https://goren.ml/uattcontract/?{k}={v}\" target=\"_blank\">Go to Leaderboard</a>'.format(k=rand_str(),v=rand_str()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f76bf",
   "metadata": {},
   "source": [
    "# Warning:\n",
    "* Since we split our training data randomly, the results can change at each run!!\n",
    "* We can avoid it by using the whole training data to produce the unique vector of words per class. (tto see how the results can change per each run, change from df_train = df_train0.copy(deep = True) to df_train = df_train0.iloc[:int(0.9*x)] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
